{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7SkKZjqblX6Y"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzkF0eI8EH0s",
        "outputId": "7eaf9818-05cf-4717-c183-d77c432c8e43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting indic-transliteration\n",
            "  Downloading indic_transliteration-2.3.44-py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.3/143.3 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting backports.functools-lru-cache (from indic-transliteration)\n",
            "  Downloading backports.functools_lru_cache-1.6.4-py2.py3-none-any.whl (5.9 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from indic-transliteration) (2022.10.31)\n",
            "Requirement already satisfied: typer in /usr/local/lib/python3.10/dist-packages (from indic-transliteration) (0.7.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from indic-transliteration) (0.10.2)\n",
            "Collecting roman (from indic-transliteration)\n",
            "  Downloading roman-4.1-py3-none-any.whl (5.5 kB)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer->indic-transliteration) (8.1.3)\n",
            "Installing collected packages: roman, backports.functools-lru-cache, indic-transliteration\n",
            "Successfully installed backports.functools-lru-cache-1.6.4 indic-transliteration-2.3.44 roman-4.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m54.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect) (1.16.0)\n",
            "Building wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993224 sha256=472b66a3f2bc334dc218fea4559622858d7b0aa301816cc7d9a13806483dcf12\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "Successfully built langdetect\n",
            "Installing collected packages: langdetect\n",
            "Successfully installed langdetect-1.0.9\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting deep_translator\n",
            "  Downloading deep_translator-1.11.1-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in /usr/local/lib/python3.10/dist-packages (from deep_translator) (4.11.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from deep_translator) (2.27.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep_translator) (2.4.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.23.0->deep_translator) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.23.0->deep_translator) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.23.0->deep_translator) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.23.0->deep_translator) (3.4)\n",
            "Installing collected packages: deep_translator\n",
            "Successfully installed deep_translator-1.11.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.29.2-py3-none-any.whl (7.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m96.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m107.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.15.1 tokenizers-0.13.3 transformers-4.29.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install indic-transliteration\n",
        "!pip install langdetect\n",
        "!pip install deep_translator\n",
        "!pip install transformers\n",
        "!pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-7oOHEs_LeXz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils  import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
        "from sklearn.model_selection import train_test_split\n",
        "from indic_transliteration import sanscript\n",
        "from langdetect import detect\n",
        "from deep_translator import *\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.svm import SVC\n",
        "import re\n",
        "import nltk\n",
        "import unicodedata\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "import transformers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "udooXmTX-Uvi"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('/content/df.csv',delimiter=',')\n",
        "data.insert(2,'converted',' ')\n",
        "data.insert(3,'preprocessed',' ')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "PIlRAqGn-Uvi"
      },
      "outputs": [],
      "source": [
        "#Preprocessing-1\n",
        "def remove_special_chars(text):\n",
        "  special_chars = ['!','\\\"','#','$','%','&',\"\\'\",'(', ')','*','+','-','.','...','/',':',';','<','=','>','?']\n",
        "  current  = text.split()\n",
        "  for i in current:\n",
        "    if i in special_chars:\n",
        "      current.remove(i)\n",
        "  return \" \".join(current)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "wDYy4GXN-Uvj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1878fd84-9427-4383-96b2-42076e3fe0b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-506c0aab2dba>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['preprocessed'][i] = remove_special_chars(data['JOKES'][i])\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(data['JOKES'])):\n",
        "  data['preprocessed'][i] = remove_special_chars(data['JOKES'][i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "MaViX5ro-Uvj"
      },
      "outputs": [],
      "source": [
        "# Detecting language kannada or english\n",
        "def check_language(word):\n",
        "    if all(unicodedata.category(c).startswith('L') for c in word):\n",
        "        if any(0x0C80 <= ord(c) <= 0x0CFF for c in word):\n",
        "            return 'Kannada'\n",
        "        else:\n",
        "            return 'English'\n",
        "    else:\n",
        "        return 'Not a word'\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "86ALqpJE-Uvj"
      },
      "outputs": [],
      "source": [
        "# Preprocessing-2\n",
        "def to_kannada(text):\n",
        "  res = []\n",
        "  for i in text.split(\" \"):\n",
        "    if check_language(i) == \"English\":\n",
        "      result = GoogleTranslator(source='auto', target='kn').translate(i)\n",
        "      res.append(result)\n",
        "    else:\n",
        "      res.append(i)\n",
        "  return \" \".join(res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "CRzCHjki-Uvk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "997f68c7-0f9f-4f85-f007-0a585ac15730"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-bd4cc9075dbc>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['converted'][i] = to_kannada(data['preprocessed'][i])\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(data['preprocessed'])):\n",
        "  \n",
        "  data['converted'][i] = to_kannada(data['preprocessed'][i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "fUmv_crL-Uvk"
      },
      "outputs": [],
      "source": [
        "sentences = data['converted'].tolist()\n",
        "labels = data['LABEL'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/AI4Bharat/indic-bert\n"
      ],
      "metadata": {
        "id": "cEPmSuSX__Mr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b2bbbc4-4fee-41d3-bf15-7bf9cb0e325e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/AI4Bharat/indic-bert\n",
            "  Cloning https://github.com/AI4Bharat/indic-bert to /tmp/pip-req-build-yopblhj5\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/AI4Bharat/indic-bert /tmp/pip-req-build-yopblhj5\n",
            "  Resolved https://github.com/AI4Bharat/indic-bert to commit d5c5c021c30fbf5af44c3e4817d497acfc11f943\n",
            "\u001b[31mERROR: git+https://github.com/AI4Bharat/indic-bert does not appear to be a Python project: neither 'setup.py' nor 'pyproject.toml' found.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers[sentencepiece]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 678
        },
        "id": "Sx1KwdqaLQAy",
        "outputId": "2f548a6e-1a11-417d-d0eb-99d92a10faaa"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers[sentencepiece] in /usr/local/lib/python3.10/dist-packages (4.29.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (0.15.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (4.65.0)\n",
            "Collecting sentencepiece!=0.1.92,>=0.1.91 (from transformers[sentencepiece])\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting protobuf<=3.20.2 (from transformers[sentencepiece])\n",
            "  Downloading protobuf-3.20.2-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m60.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers[sentencepiece]) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers[sentencepiece]) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[sentencepiece]) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[sentencepiece]) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[sentencepiece]) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[sentencepiece]) (3.4)\n",
            "Installing collected packages: sentencepiece, protobuf\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.12.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 3.20.2 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 3.20.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed protobuf-3.20.2 sentencepiece-0.1.99\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch\n",
        "\n",
        "# Tokenize the sentences using DistilBERT tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "encoded_dict = tokenizer.batch_encode_plus(\n",
        "    sentences,\n",
        "    add_special_tokens=True,\n",
        "    max_length=64,\n",
        "    padding='max_length',\n",
        "    truncation=True,\n",
        "    return_attention_mask=True,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "input_ids = encoded_dict['input_ids']\n",
        "attention_masks = encoded_dict['attention_mask']\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Create a TensorDataset\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# Split the dataset into train, validation, and test sets\n",
        "train_ratio = 0.8\n",
        "val_ratio = 0.1\n",
        "test_ratio = 0.1\n",
        "\n",
        "train_size = int(train_ratio * len(dataset))\n",
        "val_size = int(val_ratio * len(dataset))\n",
        "test_size = len(dataset) - train_size - val_size\n",
        "\n",
        "train_dataset, temp_dataset = train_test_split(dataset, train_size=train_size, test_size=(val_size + test_size))\n",
        "val_dataset, test_dataset = train_test_split(temp_dataset, train_size=val_size, test_size=test_size)\n",
        "\n",
        "# Define the model\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    'distilbert-base-uncased',\n",
        "    num_labels=2,\n",
        "    output_attentions=False,\n",
        "    output_hidden_states=False\n",
        ")\n",
        "\n",
        "# Set up the optimizer, scheduler, and batch size\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5, eps=1e-8)\n",
        "epochs = 10\n",
        "total_steps = len(train_dataset) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
        "batch_size = 32\n",
        "\n",
        "# Create DataLoader for training, validation, and test sets\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset,\n",
        "    sampler=torch.utils.data.RandomSampler(train_dataset),\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "validation_dataloader = DataLoader(\n",
        "    val_dataset,\n",
        "    sampler=torch.utils.data.SequentialSampler(val_dataset),\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "test_dataloader = DataLoader(\n",
        "    test_dataset,\n",
        "    sampler=torch.utils.data.SequentialSampler(test_dataset),\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "# Train the DistilBERT model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "print('Training DistilBERT model...')\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "\n",
        "    for batch in train_dataloader:\n",
        "        batch_input_ids = batch[0].to(device)\n",
        "        batch_attention_masks = batch[1].to(device)\n",
        "        batch_labels = batch[2].to(device)\n",
        "\n",
        "        model.zero_grad()\n",
        "\n",
        "        outputs = model(\n",
        "            batch_input_ids,\n",
        "            attention_mask=batch_attention_masks,\n",
        "            labels=batch_labels\n",
        "        )\n",
        "\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    # Evaluate the model on the validation set\n",
        "    model.eval()\n",
        "\n",
        "    val_loss = 0\n",
        "    val_accuracy = 0\n",
        "\n",
        "    for batch in validation_dataloader:\n",
        "        batch_input_ids = batch[0].to(device)\n",
        "        batch_attention_masks = batch[1].to(device)\n",
        "        batch_labels = batch[2].to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(\n",
        "                batch_input_ids,\n",
        "                attention_mask=batch_attention_masks,\n",
        "                labels=batch_labels\n",
        "            )\n",
        "\n",
        "        loss = outputs.loss\n",
        "        logits = outputs.logits\n",
        "\n",
        "        val_loss += loss.item()\n",
        "\n",
        "        preds = torch.argmax(logits, dim=1).flatten()\n",
        "        accuracy = (preds == batch_labels).cpu().numpy().mean()\n",
        "        val_accuracy += accuracy\n",
        "\n",
        "    avg_val_loss = val_loss / len(validation_dataloader)\n",
        "    avg_val_accuracy = val_accuracy / len(validation_dataloader)\n",
        "\n",
        "    print(f'Epoch {epoch + 1}/{epochs}')\n",
        "    print(f'Training Loss: {loss.item():.3f}')\n",
        "    print(f'Validation Loss: {avg_val_loss:.3f}')\n",
        "    print(f'Validation Accuracy: {avg_val_accuracy:.3f}')\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "model.eval()\n",
        "\n",
        "test_loss = 0\n",
        "test_accuracy = 0\n",
        "\n",
        "for batch in test_dataloader:\n",
        "    batch_input_ids = batch[0].to(device)\n",
        "    batch_attention_masks = batch[1].to(device)\n",
        "    batch_labels = batch[2].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(\n",
        "            batch_input_ids,\n",
        "            attention_mask=batch_attention_masks,\n",
        "            labels=batch_labels\n",
        "        )\n",
        "\n",
        "    loss = outputs.loss\n",
        "    logits = outputs.logits\n",
        "\n",
        "    test_loss += loss.item()\n",
        "\n",
        "    preds = torch.argmax(logits, dim=1).flatten()\n",
        "    accuracy = (preds == batch_labels).cpu().numpy().mean()\n",
        "    test_accuracy += accuracy\n",
        "\n",
        "avg_test_loss = test_loss / len(test_dataloader)\n",
        "avg_test_accuracy = test_accuracy / len(test_dataloader)\n",
        "\n",
        "print('Test Loss:', avg_test_loss)\n",
        "print('Test Accuracy:', avg_test_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-U9DDrSweaTt",
        "outputId": "6bc3f3e4-6a61-46f5-ab16-bbd6d7ae31a4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-ec22908113a2>:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  labels = torch.tensor(labels)\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.weight', 'pre_classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training DistilBERT model...\n",
            "Epoch 1/10\n",
            "Training Loss: 0.647\n",
            "Validation Loss: 0.567\n",
            "Validation Accuracy: 0.786\n",
            "Epoch 2/10\n",
            "Training Loss: 0.743\n",
            "Validation Loss: 0.536\n",
            "Validation Accuracy: 0.786\n",
            "Epoch 3/10\n",
            "Training Loss: 0.912\n",
            "Validation Loss: 0.615\n",
            "Validation Accuracy: 0.771\n",
            "Epoch 4/10\n",
            "Training Loss: 0.743\n",
            "Validation Loss: 0.521\n",
            "Validation Accuracy: 0.771\n",
            "Epoch 5/10\n",
            "Training Loss: 0.827\n",
            "Validation Loss: 0.558\n",
            "Validation Accuracy: 0.731\n",
            "Epoch 6/10\n",
            "Training Loss: 0.942\n",
            "Validation Loss: 0.642\n",
            "Validation Accuracy: 0.715\n",
            "Epoch 7/10\n",
            "Training Loss: 0.544\n",
            "Validation Loss: 0.414\n",
            "Validation Accuracy: 0.842\n",
            "Epoch 8/10\n",
            "Training Loss: 0.780\n",
            "Validation Loss: 0.541\n",
            "Validation Accuracy: 0.715\n",
            "Epoch 9/10\n",
            "Training Loss: 0.995\n",
            "Validation Loss: 0.681\n",
            "Validation Accuracy: 0.715\n",
            "Epoch 10/10\n",
            "Training Loss: 0.643\n",
            "Validation Loss: 0.474\n",
            "Validation Accuracy: 0.771\n",
            "Test Loss: 0.35717904567718506\n",
            "Test Accuracy: 0.8295454545454546\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Initialize empty lists for true and predicted labels\n",
        "true_labels = []\n",
        "predicted_labels = []\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "model.eval()\n",
        "\n",
        "test_loss = 0\n",
        "test_accuracy = 0\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "for batch in test_dataloader:\n",
        "    batch_input_ids = batch[0].to(device)\n",
        "    batch_attention_masks = batch[1].to(device)\n",
        "    batch_labels = batch[2].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(\n",
        "            input_ids=batch_input_ids,\n",
        "            attention_mask=batch_attention_masks\n",
        "        )\n",
        "\n",
        "    logits = outputs.logits\n",
        "\n",
        "    loss = criterion(logits, batch_labels)\n",
        "    test_loss += loss.item()\n",
        "\n",
        "    preds = torch.argmax(logits, dim=1).flatten()\n",
        "    accuracy = (preds == batch_labels).cpu().numpy().mean()\n",
        "    test_accuracy += accuracy\n",
        "\n",
        "    true_labels += batch_labels.tolist()\n",
        "    predicted_labels += preds.tolist()\n",
        "\n",
        "avg_test_loss = test_loss / len(test_dataloader)\n",
        "avg_test_accuracy = test_accuracy / len(test_dataloader)\n",
        "\n",
        "print('Test Loss:', avg_test_loss)\n",
        "print('Test Accuracy:', avg_test_accuracy)\n",
        "\n",
        "# Generate confusion matrix\n",
        "cm = confusion_matrix(true_labels, predicted_labels)\n",
        "print('Confusion Matrix:')\n",
        "print(cm)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2o6cTEnTfsLV",
        "outputId": "98aa7862-35c0-467a-acc9-adc45e159260"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.35717904567718506\n",
            "Test Accuracy: 0.8295454545454546\n",
            "Confusion Matrix:\n",
            "[[22  1]\n",
            " [ 8 12]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "model.eval()\n",
        "\n",
        "test_preds = []\n",
        "test_labels = []\n",
        "\n",
        "for batch in test_dataloader:\n",
        "    batch_input_ids = batch[0].to(device)\n",
        "    batch_attention_masks = batch[1].to(device)\n",
        "    batch_labels = batch[2].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(\n",
        "            input_ids=batch_input_ids,\n",
        "            attention_mask=batch_attention_masks\n",
        "        )\n",
        "\n",
        "    logits = outputs.logits\n",
        "\n",
        "    preds = torch.argmax(logits, dim=1).flatten()\n",
        "    test_preds.extend(preds.cpu().numpy())\n",
        "    test_labels.extend(batch_labels.cpu().numpy())\n",
        "\n",
        "# Generate confusion matrix\n",
        "cm = confusion_matrix(test_labels, test_preds)\n",
        "\n",
        "# Define class labels\n",
        "class_labels = ['Non-Humor', 'Humor']\n",
        "fig, ax = plt.subplots(figsize=(8, 8))\n",
        "\n",
        "# Plot confusion matrix\n",
        "sns.heatmap(cm, annot=True, fmt='d',\n",
        "            xticklabels=class_labels, yticklabels=class_labels)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 696
        },
        "id": "EPnSSXTxnnES",
        "outputId": "4ab976b1-8291-4066-d6bc-64cdf7bd8147"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAApUAAAKnCAYAAADX47YBAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABFKklEQVR4nO3deViVdf7/8dcB5YCIoMUipahprqilZmamlmU2maZtZqmjbaa5oJb0HZcsJZ2xVdOaJrEpzRalsobGKDXXcqFtjFwwcxS3VAQTkXP//ujnmU6gcviA9zmc5+O67uvy3Ode3jBjvXt97s/ndliWZQkAAAAwEGR3AQAAAPB/NJUAAAAwRlMJAAAAYzSVAAAAMEZTCQAAAGM0lQAAADBGUwkAAABjNJUAAAAwRlMJAAAAY1XsLqAiFB7cYXcJACpIWHwnu0sAUEFOnfyvbfe2s3eoemED2+5dnkgqAQAAYKxSJpUAAABecRXZXYHfI6kEAACAMZpKAAAAGGP4GwAAwHLZXYHfI6kEAACAMZJKAAAAF0mlKZJKAAAAGCOpBAAAAc/imUpjJJUAAAAwRlMJAAAAYwx/AwAAMFHHGEklAAAAjJFUAgAAMFHHGEklAAAAjNFUAgAAwBjD3wAAAK4iuyvweySVAAAAMEZSCQAAwEQdYySVAAAAMEZSCQAAwOLnxkgqAQAAYIymEgAAAMYY/gYAAAHPYqKOMZJKAAAAGCOpBAAAYKKOMZJKAAAAGKOpBAAAgDGGvwEAAJioY4ykEgAAAMZIKgEAAFxFdlfg90gqAQAAYIykEgAAgGcqjZFUAgAAwBhNJQAAAIwx/A0AAMAbdYyRVAIAAMAYSSUAAAATdYyRVAIAAMAYTSUAAACMMfwNAADARB1jJJUAAAAwRlIJAAACnmXx7m9TJJUAAAAwRlIJAADAkkLGSCoBAABgjKYSAAAAxhj+BgAAYEkhYySVAAAAMEZSCQAAwEQdYySVAAAAMEZTCQAAAGMMfwMAALh4o44pkkoAAAA/kZKSonbt2ikiIkIxMTHq3bu3srKyPI45ceKEhg0bpgsuuEDVq1dX3759tW/fvrNe17IsTZw4UbVr11ZYWJi6deumrVu3elUbTSUAAIDlsm/zwooVKzRs2DCtW7dOy5YtU2FhoW644Qbl5+e7jxk9erQ+/PBDvfPOO1qxYoX27NmjPn36nPW6M2bM0AsvvKC5c+dq/fr1Cg8PV/fu3XXixIlS1+awLMvy6qfxA4UHd9hdAoAKEhbfye4SAFSQUyf/a9u9T3z5jm33Dr3i9jKfe+DAAcXExGjFihW65pprdPToUUVHR2vBggW67bbbJEk//PCDmjZtqrVr1+rKK68sdg3LshQfH68xY8Zo7NixkqSjR48qNjZWqampuuuuu0pVC0klAACAy2XbVlBQoNzcXI+toKCgVGUfPXpUklSrVi1J0saNG1VYWKhu3bq5j2nSpInq1q2rtWvXlniN7Oxs5eTkeJwTGRmp9u3bn/GcktBUAgAA2CglJUWRkZEeW0pKyjnPc7lcGjVqlDp27KgWLVpIknJychQSEqKoqCiPY2NjY5WTk1PidU7vj42NLfU5JWH2NwAAgI2Sk5OVlJTksc/pdJ7zvGHDhum7777TqlWrKqo0r9BUAgAA2PhGHafTWaom8veGDx+upUuXauXKlbr44ovd++Pi4nTy5EkdOXLEI63ct2+f4uLiSrzW6f379u1T7dq1Pc5p3bp1qWti+BsAAMBPWJal4cOHa8mSJfrss89Uv359j+/btGmjqlWrKiMjw70vKytLu3btUocOHUq8Zv369RUXF+dxTm5urtavX3/Gc0pCUgkAAODyj3d/Dxs2TAsWLND777+viIgI9zOPkZGRCgsLU2RkpIYMGaKkpCTVqlVLNWrU0COPPKIOHTp4zPxu0qSJUlJSdOutt8rhcGjUqFF66qmn1KhRI9WvX18TJkxQfHy8evfuXeraaCoBAAD8xJw5cyRJXbp08dg/b948DRo0SJL07LPPKigoSH379lVBQYG6d++ul156yeP4rKws98xxSXr00UeVn5+vBx54QEeOHNHVV1+t9PR0hYaGlro21qkE4FdYpxKovGxdp3L1m7bdO7Rjf9vuXZ5IKgEAAPxk+NuXMVEHAAAAxkgqAQBAwLOsIrtL8HsklQAAADBGUwkAAABjDH8DAAAwUccYSSUAAACMkVQCAADY+O7vyoKkEgAAAMZIKgEAAHim0hhJJQAAAIzRVAIAAMAYw98AAABM1DFGUgkAAABjJJUAAABM1DFGUgkAAABjNJUAAAAwxvA3AAAAE3WMkVQCAADAGEklAAAAE3WMkVQCAADAGEklAAAASaUxkkoAAAAYo6kEAACAMYa/AQAAWFLIGEklAAAAjJFUAgAAMFHHGEklAAAAjNFUAgAAwBjD3wAAAEzUMUZSCQAAAGMklQAAAEzUMUZSCQAAAGMklQAAADxTaYykEgAAAMZoKgEAAGCM4W8AAAAm6hgjqQQAAIAxkkoAAACSSmMklQAAADBGUwkAAABjDH8DAABYlt0V+D2SSgAAABgjqQQAAGCijjGSSgAAABgjqQQAACCpNEZSCQAAAGM0lQAAADDG8DcAAIDF8LcpkkoAAAAYI6kEAABgoo4xkkoAAAAYs72pPHXqlF5//XXt27fP7lIAAABQRrY3lVWqVNFDDz2kEydO2F0KAAAIVJZl31ZJ2N5UStIVV1yhzMxMu8sAAABAGfnERJ2HH35YSUlJ+vnnn9WmTRuFh4d7fN+yZUubKgMAAAGBiTrGfKKpvOuuuyRJI0aMcO9zOByyLEsOh0NFRUV2lQYAAIBS8ImmMjs72+4SAABAICOpNOYTTWVCQoLdJQAAAMCATzSVkrR9+3Y999xz2rJliySpWbNmGjlypC655BKbKwMAAMC5+MTs708++UTNmjXTl19+qZYtW6ply5Zav369mjdvrmXLltldHgAAqOwsl31bJeETSeX48eM1evRoPf3008X2P/bYY7r++uttqgwAAACl4RNJ5ZYtWzRkyJBi+wcPHqz//Oc/NlQEAAACieWybNsqC59oKqOjo0tc/DwzM1MxMTHnvyAAAAAftHLlSvXs2VPx8fFyOBxKS0vz+N7hcJS4/fWvfz3jNSdPnlzs+CZNmnhdm08Mf99///164IEHtGPHDl111VWSpNWrV2v69OlKSkqyuToAAADfkJ+fr1atWmnw4MHq06dPse/37t3r8flf//qXhgwZor59+571us2bN9enn37q/lylivctok80lRMmTFBERIRmzpyp5ORkSVJ8fLwmT57ssSA6AABAhfCTdSp79OihHj16nPH7uLg4j8/vv/++unbtqgYNGpz1ulWqVCl2rrd8oql0OBwaPXq0Ro8erWPHjkmSIiIibK4KAACg4hUUFKigoMBjn9PplNPpNLruvn379NFHH2n+/PnnPHbr1q2Kj49XaGioOnTooJSUFNWtW9er+/nEM5W/FxERQUMJAADOLxuXFEpJSVFkZKTHlpKSYvwjzZ8/XxERESUOk/9e+/btlZqaqvT0dM2ZM0fZ2dnq1KmTO+grLZ9IKg8dOqSJEyfq888/1/79++X6QwT9yy+/2FQZAABAxUpOTi42h8Q0pZSk1157Tf3791doaOhZj/v9cHrLli3Vvn17JSQk6O233y5xdZ4z8Ymm8t5779W2bds0ZMgQxcbGyuFw2F0SAAAIJDYu7VMeQ91/9MUXXygrK0uLFi3y+tyoqChdeuml2rZtm1fn+URT+cUXX2jVqlVq1aqV3aUAAAD4vX/84x9q06ZNmXqrvLw8bd++Xffee69X5/nEM5VNmjTRr7/+ancZAAAAPi0vL0+ZmZnu9b2zs7OVmZmpXbt2uY/Jzc3VO++8o/vuu6/Ea1x33XWaNWuW+/PYsWO1YsUK7dy5U2vWrNGtt96q4OBg9evXz6vafCKpfOmllzR+/HhNnDhRLVq0UNWqVT2+r1Gjhk2VAQCAgOAnSwpt2LBBXbt2dX8+/SzmwIEDlZqaKkl66623ZFnWGZvC7du36+DBg+7Pu3fvVr9+/XTo0CFFR0fr6quv1rp16xQdHe1VbQ7Lsmx/P9DWrVt19913a9OmTR77LcuSw+FQUVGRV9crPLijPMsD4EPC4jvZXQKACnLq5H9tu/fxFx+27d7VHnnJtnuXJ59IKvv376+qVatqwYIFTNQBAADnn58klb7MJ5rK7777Tps3b1bjxo3tLgUAAABl4BMTddq2bauff/7Z7jIAAABQRj6RVD7yyCMaOXKkxo0bp8TExGITdVq2bGlTZQAAICDYP8XE7/lEU3nnnXdKkgYPHuze53A4yjxRBwAAAOeXTzSV2dnZdpcAAAACGRN1jPlEU5mQkGB3CQAAADDgE03l66+/ftbvBwwYcJ4qAQAAQFn4RFM5cuRIj8+FhYU6fvy4QkJCVK1aNZpKAABQsVxM1DHlE03l4cOHi+3bunWrhg4dqnHjxtlQEXzN319fpE9XrFb2T7sV6gxR68RmGj10sOonXCxJOpp7TLNf/afWfLlJe/cdUM2akbq2Uwc9cv8ARVQPt7l6AN7odHV7jRkzVJdflqj4+Dj1uW2wPvjgE7vLAnAOPrFOZUkaNWqkp59+uliKicC0IfNb9evTUwteeVavPDdNhadO6YHR/6fjv56QJO0/eEj7D/6iscPv05J/ztHU/0vS6vUbNTHlWZsrB+Ct8PBq+uab/+iRkf9ndykIJJbLvq2S8Imk8kyqVKmiPXv22F0GfMDLzzzl8Xnq/yXpmpv76T9ZW9W2daIaNain56b9xf193YvjNeKBgRo/ZYZOnSpSlSrB57tkAGWU/snnSv/kc7vLAOAln2gqP/jgA4/PlmVp7969mjVrljp27GhTVfBlefnHJUmRNSLOeMyxvHxVD69GQwkAODeeqTTmE01l7969PT47HA5FR0fr2muv1cyZM+0pCj7L5XLp6edf1mUtm6lRg3olHnP4yFG9nLpQt93S4/wWBwBAgPKJptJlsOBoQUGBCgoKPPYFFRTI6XSalgUf9dTM2dq2Y6den/O3Er/Py8/Xw+Mm6ZL6dfXwkHvOc3UAAAQmn52oU1opKSmKjIz02KY/P9fuslBBps58SSvWfKnXXpyuuJjoYt/n5x/Xg0kTFF4tTM9Pm6CqVXziv5sAAD7Ocrls2yoLW/+Nm5SUVKrjnnnmmTN+l5ycXOw6Qcf+a1QXfI9lWZr2zBxlrFyjebOm6+L4uGLH5OXn68HRf1HVkKp6cfokOZ0hNlQKAEBgsrWp3Lx5s8fnVatWqU2bNgoLC3PvczgcZ72G0+ksNtRdePJg+RUJn/DUzNn6eNlyvfD0RIVXC9PBQ79IkqpXD1eo06m8/Hw9MOr/9GtBgZ6fOE75+ceV//8n89SMilRwMJN1AH8RHl5NDRvWd3+uX6+uWrVqrl9+Oayff2ZFEFQQJuoYc1iW5TO/xYiICH399ddq0KCB0XUKD+4op4rgK1p0LHnCzVOPJ6n3n67Xl5u+0eBHHivxmE/eTdVFtWMrsjycR2HxnewuARWs8zUdlPHpu8X2z3/9bQ25b7QNFeF8OXXSvpHG/Kn2vb0v/P/O/rpqf8EDZ/AL363+11m/v+Lyluc8BoB/WLFyraqEXGR3GQC8RFMJAABQid5sYxe/n/0NAAAA+9maVH7zzTceny3L0g8//KC8vDyP/S1btjyfZQEAgEDDRB1jtjaVrVu3lsPh0O/nCt18882S5N7vcDhUVFRkV4kAAAAoBVubyuzsbDtvDwAA8JtKtAi5XWxtKhMSEuy8PQAAAMqJz03USUxM1M8//2x3GQAAAPCCzy0ptHPnThUWFtpdBgAACCRM1DHmc0klAAAA/I/PJZWdOnXyePc3AABAhWPxc2M+11R+/PHHdpcAAAAAL/lMU7l161Z9/vnn2r9/v1x/mNY/ceJEm6oCAABAafhEU/n3v/9dQ4cO1YUXXqi4uDg5HA73dw6Hg6YSAABULCbqGPOJpvKpp57S1KlT9dhjj9ldCgAAAMrAJ5rKw4cP6/bbb7e7DAAAEKAs3qhjzCeWFLr99tv173//2+4yAAAAUEY+kVQ2bNhQEyZM0Lp165SYmKiqVat6fD9ixAibKgMAAAGBZyqNOSzLsv23WL9+/TN+53A4tGPHDq+uV3jQu+MB+I+w+E52lwCggpw6+V/b7p33WB/b7l19+mLb7l2efCKpzM7OtrsEAAAAGPCJpvL3Tgenv19WCAAAoEIx/G3MJybqSNLrr7+uxMREhYWFKSwsTC1bttQ///lPu8sCAABAKfhEUvnMM89owoQJGj58uDp27ChJWrVqlR566CEdPHhQo0ePtrlCAABQqfHub2M+0VS++OKLmjNnjgYMGODed8stt6h58+aaPHkyTSUAAICP84nh77179+qqq64qtv+qq67S3r17bagIAAAA3vCJprJhw4Z6++23i+1ftGiRGjVqZENFAAAgoLgs+7ZKwieGv5944gndeeedWrlypfuZytWrVysjI6PEZhMAAAC+xSeayr59+2r9+vV65plnlJaWJklq2rSpvvzyS1122WX2FgcAACo9qxIlhnbxiaZSktq0aaM333zT7jIAAABQBrY2lUFBQedc5NzhcOjUqVPnqSIAABCQSCqN2dpULlmy5IzfrV27Vi+88IJcLtaNAgAA8HW2NpW9evUqti8rK0vjx4/Xhx9+qP79+2vKlCk2VAYAAABv+MSSQpK0Z88e3X///UpMTNSpU6eUmZmp+fPnKyEhwe7SAABAZedy2bdVErY3lUePHtVjjz2mhg0b6vvvv1dGRoY+/PBDtWjRwu7SAAAAUEq2Dn/PmDFD06dPV1xcnBYuXFjicDgAAECFY6KOMYdlWbb9FoOCghQWFqZu3bopODj4jMctXrzYq+sWHtxhWhoAHxUW38nuEgBUkFMn/2vbvY893MO2e0e89C/b7l2ebE0qBwwYcM4lhQAAAOD7bG0qU1NT7bw9AADAbxj+Nmb7RB0AAAD4P595TSMAAIBdbJxiUmmQVAIAAMAYSSUAAADPVBojqQQAAIAxmkoAAAA/sXLlSvXs2VPx8fFyOBxKS0vz+H7QoEFyOBwe24033njO686ePVv16tVTaGio2rdvry+//NLr2mgqAQAAXJZ9mxfy8/PVqlUrzZ49+4zH3Hjjjdq7d697W7hw4VmvuWjRIiUlJWnSpEnatGmTWrVqpe7du2v//v1e1cYzlQAAAH6iR48e6tHj7G//cTqdiouLK/U1n3nmGd1///3685//LEmaO3euPvroI7322msaP358qa9DUgkAAAKe5bJs2woKCpSbm+uxFRQUlPlnWb58uWJiYtS4cWMNHTpUhw4dOuOxJ0+e1MaNG9WtWzf3vqCgIHXr1k1r16716r40lQAAADZKSUlRZGSkx5aSklKma9144416/fXXlZGRoenTp2vFihXq0aOHioqKSjz+4MGDKioqUmxsrMf+2NhY5eTkeHVvhr8BAABslJycrKSkJI99TqezTNe666673H9OTExUy5Ytdckll2j58uW67rrrjOo8F5pKAAAAG9epdDqdZW4iz6VBgwa68MILtW3bthKbygsvvFDBwcHat2+fx/59+/Z59VymxPA3AABApbV7924dOnRItWvXLvH7kJAQtWnTRhkZGe59LpdLGRkZ6tChg1f3oqkEAABw2bh5IS8vT5mZmcrMzJQkZWdnKzMzU7t27VJeXp7GjRundevWaefOncrIyFCvXr3UsGFDde/e3X2N6667TrNmzXJ/TkpK0t///nfNnz9fW7Zs0dChQ5Wfn++eDV5aDH8DAAD4iQ0bNqhr167uz6efxRw4cKDmzJmjb775RvPnz9eRI0cUHx+vG264QU8++aTH8Pr27dt18OBB9+c777xTBw4c0MSJE5WTk6PWrVsrPT292OSdc3FYllXpXnZZeHCH3SUAqCBh8Z3sLgFABTl18r+23ftI/2ttu3fUm5/Zdu/yxPA3AAAAjNFUAgAAwBjPVAIAANi4pFBlQVIJAAAAYySVAAAAXi7tg+JIKgEAAGCMphIAAADGGP4GAAABz2KijjGSSgAAABgjqQQAAGCijjGSSgAAABijqQQAAIAxhr8BAEDAY6KOOZJKAAAAGCOpBAAAYKKOMZJKAAAAGCOpBAAAAc8iqTRGUgkAAABjNJUAAAAwxvA3AAAAw9/GSCoBAABgjKQSAAAEPCbqmCOpBAAAgDGaSgAAABhj+BsAAIDhb2MklQAAADBGUgkAAAIeE3XMkVQCAADAGEklAAAIeCSV5kgqAQAAYIymEgAAAMYY/gYAAAGP4W9zJJUAAAAwRlIJAABgOeyuwO+RVAIAAMAYTSUAAACMMfwNAAACHhN1zJFUAgAAwBhJJQAACHiWi4k6pkgqAQAAYIykEgAABDyeqTRHUgkAAABjNJUAAAAwxvA3AAAIeBZv1DFGUgkAAABjJJUAACDgMVHHHEklAAAAjNFUAgAAwBjD3wAAIODxRh1zJJUAAAAwRlIJAAACnmXZXYH/I6kEAACAMZJKAAAQ8Him0hxJJQAAAIzRVAIAAMAYw98AACDgMfxtjqQSAAAAxkgqAQBAwGNJIXMklQAAADBGUwkAAABjDH8DAICAx0QdcySVAAAAMEZTCQAAAp5lOWzbvLFy5Ur17NlT8fHxcjgcSktLc39XWFioxx57TImJiQoPD1d8fLwGDBigPXv2nPWakydPlsPh8NiaNGni9e+QphIAAMBP5Ofnq1WrVpo9e3ax744fP65NmzZpwoQJ2rRpkxYvXqysrCzdcsst57xu8+bNtXfvXve2atUqr2vjmUoAABDwLJfdFZROjx491KNHjxK/i4yM1LJlyzz2zZo1S1dccYV27dqlunXrnvG6VapUUVxcnFFtJJUAAAA2KigoUG5ursdWUFBQLtc+evSoHA6HoqKiznrc1q1bFR8frwYNGqh///7atWuX1/eiqQQAALBRSkqKIiMjPbaUlBTj6544cUKPPfaY+vXrpxo1apzxuPbt2ys1NVXp6emaM2eOsrOz1alTJx07dsyr+zksq/KtIV94cIfdJQCoIGHxnewuAUAFOXXyv7bd+8emN9p274TM94slk06nU06n86znORwOLVmyRL179y72XWFhofr27avdu3dr+fLlZ20q/+jIkSNKSEjQM888oyFDhpT6PJ6pBAAAsFFpGkhvFBYW6o477tBPP/2kzz77zKuGUpKioqJ06aWXatu2bV6dx/A3AAAIeP6ypNC5nG4ot27dqk8//VQXXHCB19fIy8vT9u3bVbt2ba/Oo6kEAADwE3l5ecrMzFRmZqYkKTs7W5mZmdq1a5cKCwt12223acOGDXrzzTdVVFSknJwc5eTk6OTJk+5rXHfddZo1a5b789ixY7VixQrt3LlTa9as0a233qrg4GD169fPq9oY/gYAAPATGzZsUNeuXd2fk5KSJEkDBw7U5MmT9cEHH0iSWrdu7XHe559/ri5dukiStm/froMHD7q/2717t/r166dDhw4pOjpaV199tdatW6fo6GivamOiDgC/wkQdoPKyc6LOD5feZNu9m/z4sW33Lk8MfwMAAMAYw98AACDgVb5x2/OPpBIAAADGSCoBAEDAs1zlu7RPICpVU3l6JlFp3HLLLWUuBgAAAP6pVE1lSa//KYnD4VBRUZFJPQAAAPBDpWoqXS5XRdcBAABgG1c5v9kmEDFRBwAAAMbKNFEnPz9fK1as0K5duzxe+yNJI0aMKJfCAAAAzpfyfgd3IPK6qdy8ebNuuukmHT9+XPn5+apVq5YOHjyoatWqKSYmhqYSAAAgAHk9/D169Gj17NlThw8fVlhYmNatW6effvpJbdq00d/+9reKqBEAAAA+zuumMjMzU2PGjFFQUJCCg4NVUFCgOnXqaMaMGXr88ccrokYAAIAKZVn2bZWF101l1apVFRT022kxMTHatWuXJCkyMlI///xz+VYHAAAAv+D1M5WXXXaZvvrqKzVq1EidO3fWxIkTdfDgQf3zn/9UixYtKqJGAACACsWSQua8TiqnTZum2rVrS5KmTp2qmjVraujQoTpw4IBeeeWVci8QAAAAvs/rpLJt27buP8fExCg9Pb1cCwIAAID/KdM6lQAAAJUJ61Sa87qprF+/vhyOM//id+zYYVQQAAAA/I/XTeWoUaM8PhcWFmrz5s1KT0/XuHHjyqsuAACA86YyLe1jF6+bypEjR5a4f/bs2dqwYYNxQQAAAPA/Xs/+PpMePXrovffeK6/LAQAAnDcuy2HbVlmUW1P57rvvqlatWuV1OQAAAPiRMi1+/vuJOpZlKScnRwcOHNBLL71UrsUBAADAP3jdVPbq1cujqQwKClJ0dLS6dOmiJk2alGtxZTWjzQS7SwBQQTIvvszuEgBUQiwpZM7rpnLy5MkVUAYAAAD8mdfPVAYHB2v//v3F9h86dEjBwcHlUhQAAMD5xEQdc143ldYZFnIqKChQSEiIcUEAAADwP6Ue/n7hhRckSQ6HQ6+++qqqV6/u/q6oqEgrV670mWcqAQAAcH6Vuql89tlnJf2WVM6dO9djqDskJET16tXT3Llzy79CAACACsYLdcyVuqnMzs6WJHXt2lWLFy9WzZo1K6woAAAA+BevZ39//vnnFVEHAACAbSrThBm7eD1Rp2/fvpo+fXqx/TNmzNDtt99eLkUBAADAv3jdVK5cuVI33XRTsf09evTQypUry6UoAACA88myHLZtlYXXTWVeXl6JSwdVrVpVubm55VIUAAAA/IvXTWViYqIWLVpUbP9bb72lZs2alUtRAAAA8C9eT9SZMGGC+vTpo+3bt+vaa6+VJGVkZGjBggV69913y71AAACAiuayu4BKwOumsmfPnkpLS9O0adP07rvvKiwsTK1atdJnn32mWrVqVUSNAAAA8HFeN5WS9Kc//Ul/+tOfJEm5ublauHChxo4dq40bN6qoqKhcCwQAAKholirPhBm7eP1M5WkrV67UwIEDFR8fr5kzZ+raa6/VunXryrM2AAAA+AmvksqcnBylpqbqH//4h3Jzc3XHHXeooKBAaWlpTNIBAAAIYKVOKnv27KnGjRvrm2++0XPPPac9e/boxRdfrMjaAAAAzguXZd9WWZQ6qfzXv/6lESNGaOjQoWrUqFFF1gQAAAA/U+qkctWqVTp27JjatGmj9u3ba9asWTp48GBF1gYAAHBeuOSwbassSt1UXnnllfr73/+uvXv36sEHH9Rbb72l+Ph4uVwuLVu2TMeOHavIOgEAAODDvJ79HR4ersGDB2vVqlX69ttvNWbMGD399NOKiYnRLbfcUhE1AgAAVChLDtu2yqLMSwpJUuPGjTVjxgzt3r1bCxcuLK+aAAAA4GeMmsrTgoOD1bt3b33wwQflcTkAAAD4mTK9UQcAAKAy4d3f5solqQQAAEBgI6kEAAABrzJNmLELSSUAAACM0VQCAADAGMPfAAAg4DFRxxxJJQAAAIyRVAIAgIBHUmmOpBIAAADGSCoBAEDAY0khcySVAAAAMEZTCQAAAGMMfwMAgIDnYvTbGEklAAAAjJFUAgCAgOdioo4xkkoAAAA/sXLlSvXs2VPx8fFyOBxKS0vz+N6yLE2cOFG1a9dWWFiYunXrpq1bt57zurNnz1a9evUUGhqq9u3b68svv/S6NppKAAAAP5Gfn69WrVpp9uzZJX4/Y8YMvfDCC5o7d67Wr1+v8PBwde/eXSdOnDjjNRctWqSkpCRNmjRJmzZtUqtWrdS9e3ft37/fq9oclmVZXp3hB6Ym9Le7BAAVpFfwUbtLAFBBWuxYatu90+Lutu3evXMWlOk8h8OhJUuWqHfv3pJ+Synj4+M1ZswYjR07VpJ09OhRxcbGKjU1VXfddVeJ12nfvr3atWunWbNmSZJcLpfq1KmjRx55ROPHjy91PSSVAAAAlUB2drZycnLUrVs3977IyEi1b99ea9euLfGckydPauPGjR7nBAUFqVu3bmc850yYqAMAAAKene/+LigoUEFBgcc+p9Mpp9Pp1XVycnIkSbGxsR77Y2Nj3d/90cGDB1VUVFTiOT/88INX9yepBAAAsFFKSooiIyM9tpSUFLvL8hpJJQAACHguh31LCiUnJyspKcljn7cppSTFxcVJkvbt26fatWu79+/bt0+tW7cu8ZwLL7xQwcHB2rdvn8f+ffv2ua9XWiSVAAAANnI6napRo4bHVpamsn79+oqLi1NGRoZ7X25urtavX68OHTqUeE5ISIjatGnjcY7L5VJGRsYZzzkTkkoAAAA/kZeXp23btrk/Z2dnKzMzU7Vq1VLdunU1atQoPfXUU2rUqJHq16+vCRMmKD4+3j1DXJKuu+463XrrrRo+fLgkKSkpSQMHDlTbtm11xRVX6LnnnlN+fr7+/Oc/e1UbTSUAAAh4/rK+4oYNG9S1a1f359PD5gMHDlRqaqoeffRR5efn64EHHtCRI0d09dVXKz09XaGhoe5ztm/froMHD7o/33nnnTpw4IAmTpyonJwctW7dWunp6cUm75wL61QC8CusUwlUXnauU/lObft6h9v3vmnbvcsTSSUAAAh4di4pVFkwUQcAAADGaCoBAABgjOFvAAAQ8Fz2LVNZaZBUAgAAwBhJJQAACHguEVWaIqkEAACAMZJKAAAQ8Crdot02IKkEAACAMZpKAAAAGGP4GwAABDyWFDJHUgkAAABjJJUAACDg8e5vcySVAAAAMEZTCQAAAGMMfwMAgIDHOpXmSCoBAABgjKQSAAAEPJYUMkdSCQAAAGM0lQAAADDG8DcAAAh4rFNpjqQSAAAAxkgqAQBAwCOpNEdSCQAAAGMklQAAIOBZLClkjKQSAAAAxmgqAQAAYIzhbwAAEPCYqGOOpBIAAADGSCoBAEDAI6k0R1IJAAAAYzSVAAAAMMbwNwAACHiW3QVUAiSVAAAAMEZSCQAAAp6LN+oYI6kEAACAMZJKAAAQ8FhSyBxJJQAAAIzRVAIAAMAYw98AACDgMfxtjqQSAAAAxkgqAQBAwGPxc3MklQAAADBGUwkAAABjDH8DAICAxxt1zJFUAgAAwBhJJQAACHgsKWSOpBIAAADGSCoBAEDAY0khcySVAAAAMEZTCQAAAGMMfwMAgIDnYgDcGEklAAAAjJFUAgCAgMeSQuZIKgEAAGCMphIAAADGGP4GAAABj2k65kgqAQAAYIykEgAABDwm6pgjqQQAAIAxkkoAABDwXA67K/B/JJUAAAAwRlMJAAAAYzSVAAAg4Llk2bZ5o169enI4HMW2YcOGlXh8ampqsWNDQ0PL41dWDM9UAgAA+ImvvvpKRUVF7s/fffedrr/+et1+++1nPKdGjRrKyspyf3Y4KuYBUppKAAAQ8Pxl8fPo6GiPz08//bQuueQSde7c+YznOBwOxcXFVXRpDH8DAADYqaCgQLm5uR5bQUHBOc87efKk3njjDQ0ePPis6WNeXp4SEhJUp04d9erVS99//315lu9GUwkAAGCjlJQURUZGemwpKSnnPC8tLU1HjhzRoEGDznhM48aN9dprr+n999/XG2+8IZfLpauuukq7d+8ux5/gNw7Lsvwl8S21qQn97S4BQAXpFXzU7hIAVJAWO5badu/kenfbdu/JWfOKJZNOp1NOp/Os53Xv3l0hISH68MMPS32vwsJCNW3aVP369dOTTz5ZpnrPhGcqAQAAbFSaBvKPfvrpJ3366adavHixV+dVrVpVl112mbZt2+bVeaXB8DcAAAh4/rKk0Gnz5s1TTEyM/vSnP3l1XlFRkb799lvVrl27TPc9G5pKAAAAP+JyuTRv3jwNHDhQVap4DjoPGDBAycnJ7s9TpkzRv//9b+3YsUObNm3SPffco59++kn33XdfudfF8DcAAAh4/jTB5NNPP9WuXbs0ePDgYt/t2rVLQUH/ywwPHz6s+++/Xzk5OapZs6batGmjNWvWqFmzZuVeFxN1APgVJuoAlZedE3UerdfPtnvP2LnQtnuXJ4a/AQAAYIzhbwAAEPBcdhdQCZBUAgAAwBhJJQAACHhlXdoH/0NSCQAAAGM0lQAAADDG8DcAAAh4DH6bI6kEAACAMZJKAAAQ8FhSyJztSWVhYaEuueQSbdmyxe5SAAAAUEa2J5VVq1bViRMn7C4DAAAEMIunKo3ZnlRK0rBhwzR9+nSdOnXK7lIAAABQBrYnlZL01VdfKSMjQ//+97+VmJio8PBwj+8XL15sU2UAAAAoDZ9oKqOiotS3b1+7ywAAAAGKiTrmfKKpnDdvnt0lAAAAwIBPNJWnHThwQFlZWZKkxo0bKzo62uaKAABAIODd3+Z8YqJOfn6+Bg8erNq1a+uaa67RNddco/j4eA0ZMkTHjx+3uzwAAACcg080lUlJSVqxYoU+/PBDHTlyREeOHNH777+vFStWaMyYMXaXBwAAgHPwieHv9957T++++666dOni3nfTTTcpLCxMd9xxh+bMmWNfcQAAoNJj8NucTySVx48fV2xsbLH9MTExDH8DAAD4AZ9oKjt06KBJkyZ5vFnn119/1RNPPKEOHTrYWBkAAAgELlm2bZWFTwx/P//88+revbsuvvhitWrVSpL09ddfKzQ0VJ988onN1QEAAOBcfKKpbNGihbZu3ao333xTP/zwgySpX79+6t+/v8LCwmyuDgAAAOfiE02lJFWrVk3333+/3WUAAIAAxBt1zPlMU7lnzx6tWrVK+/fvl8vl+T/tiBEjbKoKvsoR5NA1o/uqxa0dFR4dpbx9h/XNuyu16oU0u0sD4KVq7Zrrwgf6KqzFJaoae4F+evApHVu27rcvqwQrdsy9iujSViF14lR0LF95q7/WvhmpOrX/F3sLB+DBJ5rK1NRUPfjggwoJCdEFF1wgh8Ph/s7hcNBUopgOQ3vq8nu66cMxc3Xgx92q3bKBbv7rAzqR+6s2pPIcLuBPgqqF6sSWHTr8zjIlzP0/z+/CnAprfon2v/iWTmzJVnBkddWe+IAS/j5B23uNtqliVEZWJZowYxefaConTJigiRMnKjk5WUFBPjEhHT7u4jaX6sdlG7Xts0xJ0tHdB9X8lg6Kb93A3sIAeC1vxUblrdhY4neuY8e1c8AEj317J8/VJWnPqmp8tAr3HDgfJQIoBZ/o4I4fP6677rqLhhKltnvjj6p3VXPVqh8nSYppWlcXt22s7cu/trkyABUtKKKaLJdLRbl5dpeCSsRl41ZZ+ERSOWTIEL3zzjsaP3683aXAT6x56UM5q4fpoc/+KleRS0HBQVr+13f0fdoau0sDUIEcIVUV9+ifdfTDlXLl/Wp3OQB+xyeaypSUFN18881KT09XYmKiqlat6vH9M888c8ZzCwoKVFBQ4LHvlFWkKo7gCqkVvqHZze3VondHpY2YrQM//lexzRJ0/aR7dGzfYX373hd2lwegIlQJVp1Z4yWHtGfCbLurAfAHPtNUfvLJJ2rcuLEkFZuoc65zn3jiCY99XWu00HVRLcu/UPiM6x6/W2vmfKj/fPjbDNEDWT8r8uILddXDt9BUApVRlWDVfXG8ql4Uo539HyelRLljoo45n2gqZ86cqddee02DBg3y+tzk5GQlJSV57Hu2xQPlVBl8VZWwEFl/WHrKKnLJEXT2/wgB4If+f0MZUi9e2f2TVXTkmN0VASiBTzSVTqdTHTt2LPO5TqfTYx9D35Xf1k83q+Pw3srdc0gHftytuOb1dMV9PfT12yvsLg2Al4KqhSokobb7c0idWIU2ra+io3kq3P+L6s5OVljzS/TTfVPkCApSlQujJElFR/NkFZ6yqWpUNpVpwoxdHJZl2Z73pqSkaO/evXrhhRfK5XpTE/qXy3Xgu0LCQ9V5zG1q3L2dql1YQ3n7Duv7D9bqi+cXy1VYZHd5qEC9go/aXQLKWXj7RNVfmFJs/+F3P9X+5xeo8RevlXhedr9k5a//tqLLw3nUYsdS2+49sF5f2+49f+d7tt27PPlEU3nrrbfqs88+0wUXXKDmzZsXm6izePFir65HUwlUXjSVQOVFU+nffGL4OyoqSn369LG7DAAAEKBc9mdsfs8nmsp58+bZXQIAAAAM+ERTCQAAYCdySnM+0VTWr1//rOtR7tix4zxWAwAAAG/5RFM5atQoj8+FhYXavHmz0tPTNW7cOHuKAgAAAcNFVmnMJ5rKkSNHlrh/9uzZ2rBhw3muBgAAAN4KsruAs+nRo4fee69yTLMHAACozHwiqTyTd999V7Vq1bK7DAAAUMnx7m9zPtFUXnbZZR4TdSzLUk5Ojg4cOKCXXnrJxsoAAABQGj7RVPbq1cujqQwKClJ0dLS6dOmiJk2a2FgZAAAIBLz725ytTWVubq4kKSkp6azH1KhR43yVBAAAgDKwtamMioo66/qUlmXJ4XCoqKjoPFYFAAAAb9naVH7++efuP1uWpZtuukmvvvqqLrroIhurAgAAgYZ1Ks3Z2lR27tzZ43NwcLCuvPJKNWjQwKaKAAAAUBY+MVEHAADATiwpZM6nFz8HAACAf/C5pPJsE3cAAAAqAksKmbO1qezTp4/H5xMnTuihhx5SeHi4x/7Fixefz7IAAADgJVubysjISI/P99xzj02VAAAAwIStTeW8efPsvD0AAICk35Y2hBkm6gAAAMCYz03UAQAAON9Y/NwcSSUAAACM0VQCAADAGMPfAAAg4LFOpTmSSgAAABgjqQQAAAGPd3+bI6kEAADwE5MnT5bD4fDYmjRpctZz3nnnHTVp0kShoaFKTEzUxx9/XCG10VQCAICA55Jl2+at5s2ba+/eve5t1apVZzx2zZo16tevn4YMGaLNmzerd+/e6t27t7777juTX1eJaCoBAAD8SJUqVRQXF+feLrzwwjMe+/zzz+vGG2/UuHHj1LRpUz355JO6/PLLNWvWrHKvi6YSAADARgUFBcrNzfXYCgoKznj81q1bFR8frwYNGqh///7atWvXGY9du3atunXr5rGve/fuWrt2bbnVfxpNJQAACHiWZdm2paSkKDIy0mNLSUkpsc727dsrNTVV6enpmjNnjrKzs9WpUycdO3asxONzcnIUGxvrsS82NlY5OTnl/jtk9jcAAICNkpOTlZSU5LHP6XSWeGyPHj3cf27ZsqXat2+vhIQEvf322xoyZEiF1nkuNJUAACDg2bn4udPpPGMTeS5RUVG69NJLtW3bthK/j4uL0759+zz27du3T3FxcWW639kw/A0AAOCn8vLytH37dtWuXbvE7zt06KCMjAyPfcuWLVOHDh3KvRaaSgAAAD8xduxYrVixQjt37tSaNWt06623Kjg4WP369ZMkDRgwQMnJye7jR44cqfT0dM2cOVM//PCDJk+erA0bNmj48OHlXhvD3wAAIOD5yxt1du/erX79+unQoUOKjo7W1VdfrXXr1ik6OlqStGvXLgUF/S8zvOqqq7RgwQL95S9/0eOPP65GjRopLS1NLVq0KPfaHJZl+cdv0QtTE/rbXQKACtIr+KjdJQCoIC12LLXt3jfUudG2e//753Tb7l2eSCoBAEDAK8ubbeCJZyoBAABgjKQSAAAEvEr4NOB5R1IJAAAAYzSVAAAAMMbwNwAACHhM1DFHUgkAAABjJJUAACDg+cvi576MpBIAAADGaCoBAABgjOFvAAAQ8FysU2mMpBIAAADGSCoBAEDAI6c0R1IJAAAAYySVAAAg4LH4uTmSSgAAABijqQQAAIAxhr8BAEDAY/jbHEklAAAAjJFUAgCAgGex+LkxkkoAAAAYo6kEAACAMYa/AQBAwGOijjmSSgAAABgjqQQAAAHPIqk0RlIJAAAAYzSVAAAAMMbwNwAACHisU2mOpBIAAADGSCoBAEDAY0khcySVAAAAMEZSCQAAAh7PVJojqQQAAIAxmkoAAAAYY/gbAAAEPCbqmCOpBAAAgDGSSgAAEPB497c5kkoAAAAYo6kEAACAMYa/AQBAwHOxTqUxkkoAAAAYI6kEAAABj4k65kgqAQAAYIykEgAABDyeqTRHUgkAAABjNJUAAAAwxvA3AAAIeEzUMUdSCQAAAGMklQAAIOAxUcccSSUAAACM0VQCAADAGMPfAAAg4DFRxxxJJQAAAIyRVAIAgIDHRB1zJJUAAAAwRlIJAAACHs9UmiOpBAAAgDGaSgAAABhj+BsAAAQ8y3LZXYLfI6kEAACAMZJKAAAQ8FxM1DFGUgkAAABjNJUAAAB+IiUlRe3atVNERIRiYmLUu3dvZWVlnfWc1NRUORwOjy00NLTca2P4GwAABDzLT96os2LFCg0bNkzt2rXTqVOn9Pjjj+uGG27Qf/7zH4WHh5/xvBo1ang0nw6Ho9xro6kEAADwE+np6R6fU1NTFRMTo40bN+qaa64543kOh0NxcXEVWhvD3wAAIOC5ZNm2mTh69KgkqVatWmc9Li8vTwkJCapTp4569eql77//3ui+JaGpBAAAsFFBQYFyc3M9toKCgnOe53K5NGrUKHXs2FEtWrQ443GNGzfWa6+9pvfff19vvPGGXC6XrrrqKu3evbs8fwyaSgAAAMuybNtSUlIUGRnpsaWkpJyz5mHDhum7777TW2+9ddbjOnTooAEDBqh169bq3LmzFi9erOjoaL388svl9euTxDOVAAAAtkpOTlZSUpLHPqfTedZzhg8frqVLl2rlypW6+OKLvbpf1apVddlll2nbtm1e13o2NJUAAAA2cjqd52wiT7MsS4888oiWLFmi5cuXq379+l7fr6ioSN9++61uuukmr889G5pKAAAQ8Fx+sqTQsGHDtGDBAr3//vuKiIhQTk6OJCkyMlJhYWGSpAEDBuiiiy5yD6FPmTJFV155pRo2bKgjR47or3/9q3766Sfdd9995VobTSUAAICfmDNnjiSpS5cuHvvnzZunQYMGSZJ27dqloKD/TZs5fPiw7r//fuXk5KhmzZpq06aN1qxZo2bNmpVrbQ7LX1b79MLUhP52lwCggvQKPmp3CQAqSIsdS227d1xUU9vunXNki233Lk/M/gYAAIAxmkoAAAAY45lKAAAQ8Crh04DnHUklAAAAjJFUAgCAgGf6Dm6QVAIAAKAckFQCAICAxzOV5kgqAQAAYIymEgAAAMYY/gYAAAHPX9797ctIKgEAAGCMpBIAAAQ8JuqYI6kEAACAMZpKAAAAGGP4GwAABDzeqGOOpBIAAADGSCoBAEDAY6KOOZJKAAAAGCOpBAAAAY/Fz82RVAIAAMAYTSUAAACMMfwNAAACnsWSQsZIKgEAAGCMpBIAAAQ8JuqYI6kEAACAMZpKAAAAGGP4GwAABDzeqGOOpBIAAADGSCoBAEDAY0khcySVAAAAMEZTCQAAAGMMfwMAgIDHRB1zJJUAAAAwRlIJAAACHkmlOZJKAAAAGCOpBAAAAY+c0hxJJQAAAIzRVAIAAMCYw+LJVPixgoICpaSkKDk5WU6n0+5yAJQj/n4D/oWmEn4tNzdXkZGROnr0qGrUqGF3OQDKEX+/Af/C8DcAAACM0VQCAADAGE0lAAAAjNFUwq85nU5NmjSJh/iBSoi/34B/YaIOAAAAjJFUAgAAwBhNJQAAAIzRVAIAAMAYTSUAAACM0VSi1AYNGiSHw6Gnn37aY39aWpocDkeF3nvnzp1yOBzKzMws9l2XLl00atSoCr0/gLMbNGiQevfuXWz/8uXL5XA4dOTIkfNeE4Dzi6YSXgkNDdX06dN1+PBhu0vxC4WFhXaXAKAEJ0+etLsEoNKhqYRXunXrpri4OKWkpJzxmPfee0/NmzeX0+lUvXr1NHPmTI/v69Wrp2nTpmnw4MGKiIhQ3bp19corr5RbjQ6HQ2lpaR77oqKilJqaKul/qefbb7+tTp06KSwsTO3atdOPP/6or776Sm3btlX16tXVo0cPHThwwH0Nl8ulKVOm6OKLL5bT6VTr1q2Vnp7u/v70dRctWqTOnTsrNDRUb775Zrn9XIC/mzx5slq3bu2x77nnnlO9evXcn08nntOmTVNsbKyioqI0ZcoUnTp1SuPGjVOtWrV08cUXa968eR7X+fbbb3XttdcqLCxMF1xwgR544AHl5eUVu+7UqVMVHx+vxo0bV+SPCgQkmkp4JTg4WNOmTdOLL76o3bt3F/t+48aNuuOOO3TXXXfp22+/1eTJkzVhwgR3Q3fazJkz1bZtW23evFkPP/ywhg4dqqysrPP0U/xm0qRJ+stf/qJNmzapSpUquvvuu/Xoo4/q+eef1xdffKFt27Zp4sSJ7uOff/55zZw5U3/729/0zTffqHv37rrlllu0detWj+uOHz9eI0eO1JYtW9S9e/fz+jMBlcFnn32mPXv2aOXKlXrmmWc0adIk3XzzzapZs6bWr1+vhx56SA8++KD7n0H5+fnq3r27atasqa+++krvvPOOPv30Uw0fPtzjuhkZGcrKytKyZcu0dOlSO340oHKzgFIaOHCg1atXL8uyLOvKK6+0Bg8ebFmWZS1ZssQ6/X+lu+++27r++us9zhs3bpzVrFkz9+eEhATrnnvucX92uVxWTEyMNWfOnDPeOzs725JkhYWFWeHh4R5bUFCQNXLkSPexkqwlS5Z4nB8ZGWnNmzfP41qvvvqq+/uFCxdakqyMjAz3vpSUFKtx48buz/Hx8dbUqVM9rtuuXTvr4Ycf9rjuc889d8afA6isBg4caAUHBxf7+xkaGmpJsg4fPmxNmjTJatWqlcd5zz77rJWQkOBxnYSEBKuoqMi9r3HjxlanTp3cn0+dOmWFh4dbCxcutCzLsl555RWrZs2aVl5envuYjz76yAoKCrJycnLc142NjbUKCgoq4KcHYFmWRVKJMpk+fbrmz5+vLVu2eOzfsmWLOnbs6LGvY8eO2rp1q4qKitz7WrZs6f6zw+FQXFyc9u/fL0nq0aOHqlevrurVq6t58+Ye11q0aJEyMzM9trZt25bpZ/h9DbGxsZKkxMREj32na8rNzdWePXtK/Nn++Dsoaz2Av+vatWuxv5+vvvqq19dp3ry5goL+96+n2NhYj7+bwcHBuuCCC9x/P7ds2aJWrVopPDzcfUzHjh3lcrk8RkASExMVEhJSlh8NQClUsbsA+KdrrrlG3bt3V3JysgYNGuT1+VWrVvX47HA45HK5JEmvvvqqfv311xKPq1Onjho2bOixLywsrNi1rD+8fbSkCTO/v/bp2et/3He6Jm/8/l9sQCAJDw8v9vfz94/JBAUFef13U/rt7+LZ/pnhTX0AKg5NJcrs6aefVuvWrT0eeG/atKlWr17tcdzq1at16aWXKjg4uFTXveiii4zqio6O1t69e92ft27dquPHjxtds0aNGoqPj9fq1avVuXNn9/7Vq1friiuuMLo2ECiio6OVk5Mjy7Lc/yFX0jJh3mratKlSU1OVn5/vbhxXr16toKAgJuQA5xHD3yizxMRE9e/fXy+88IJ735gxY5SRkaEnn3xSP/74o+bPn69Zs2Zp7Nix562ua6+9VrNmzdLmzZu1YcMGPfTQQ8VSjrIYN26cpk+frkWLFikrK0vjx49XZmamRo4cWQ5VA5Vfly5ddODAAc2YMUPbt2/X7Nmz9a9//cv4uv3791doaKgGDhyo7777Tp9//rkeeeQR3Xvvve5HWwBUPJpKGJkyZYrHENTll1+ut99+W2+99ZZatGihiRMnasqUKWUaIi+rmTNnqk6dOurUqZPuvvtujR07VtWqVTO+7ogRI5SUlKQxY8YoMTFR6enp+uCDD9SoUaNyqBqo/Jo2baqXXnpJs2fPVqtWrfTll1+Wy39wVqtWTZ988ol++eUXtWvXTrfddpuuu+46zZo1qxyqBlBaDuuPD7gAAAAAXiKpBAAAgDGaSgAAABijqQQAAIAxmkoAAAAYo6kEAACAMZpKAAAAGKOpBAAAgDGaSgA+a9CgQerdu7f7c5cuXTRq1KjzXsfy5cvlcDh05MiR835vAPAXNJUAvDZo0CA5HA45HA6FhISoYcOGmjJlik6dOlWh9128eLGefPLJUh1LIwgA51cVuwsA4J9uvPFGzZs3TwUFBfr44481bNgwVa1aVcnJyR7HnTx5UiEhIeVyz1q1apXLdQAA5Y+kEkCZOJ1OxcXFKSEhQUOHDlW3bt30wQcfuIesp06dqvj4eDVu3FiS9PPPP+uOO+5QVFSUatWqpV69emnnzp3u6xUVFSkpKUlRUVG64IIL9Oijj+qPb5H94/B3QUGBHnvsMdWpU0dOp1MNGzbUP/7xD+3cuVNdu3aVJNWsWVMOh8P9/nmXy6WUlBTVr19fYWFhatWqld59912P+3z88ce69NJLFRYWpq5du3rUCQAoGU0lgHIRFhamkydPSpIyMjKUlZWlZcuWaenSpSosLFT37t0VERGhL774QqtXr1b16tV14403us+ZOXOmUlNT9dprr2nVqlX65ZdftGTJkrPec8CAAVq4cKFeeOEFbdmyRS+//LKqV6+uOnXq6L333pMkZWVlae/evXr++eclSSkpKXr99dc1d+5cff/99xo9erTuuecerVixQtJvzW+fPn3Us2dPZWZm6r777tP48eMr6tcGAJUGw98AjFiWpYyMDH3yySd65JFHdODAAYWHh+vVV191D3u/8cYbcrlcevXVV+VwOCRJ8+bNU1RUlJYvX64bbrhBzz33nJKTk9WnTx9J0ty5c/XJJ5+c8b4//vij3n77bS1btkzdunWTJDVo0MD9/emh8piYGEVFRUn6LdmcNm2aPv30U3Xo0MF9zqpVq/Tyyy+rc+fOmjNnji655BLNnDlTktS4cWN9++23mj59ejn+1gCg8qGpBFAmS5cuVfXq1VVYWCiXy6W7775bkydP1rBhw5SYmOjxHOXXX3+tbdu2KSIiwuMaJ06c0Pbt23X06FHt3btX7du3d39XpUoVtW3bttgQ+GmZmZkKDg5W586dS13ztm3bdPz4cV1//fUe+0+ePKnLLrtMkrRlyxaPOiS5G1AAwJnRVAIok65du2rOnDkKCQlRfHy8qlT53z9OwsPDPY7Ny8tTmzZt9Oabbxa7TnR0dJnuHxYW5vU5eXl5kqSPPvpIF110kcd3TqezTHUAAH5DUwmgTMLDw9WwYcNSHXv55Zdr0aJFiomJUY0aNUo8pnbt2lq/fr2uueYaSdKpU6e0ceNGXX755SUen5iYKJfLpRUrVriHv3/vdFJaVFTk3tesWTM5nU7t2rXrjAln06ZN9cEHH3jsW7du3bl/SAAIcEzUAVDh+vfvrwsvvFC9evXSF198oezsbC1fvlwjRozQ7t27JUkjR47U008/rbS0NP3www96+OGHz7rGZL169TRw4EANHjxYaWlp7mu+/fbbkqSEhAQ5HA4tXbpUBw4cUF5eniIiIjR27FiNHj1a8+fP1/bt27Vp0ya9+OKLmj9/viTpoYce0tatWzVu3DhlZWVpwYIFSk1NrehfEQD4PZpKABWuWrVqWrlyperWras+ffqoadOmGjJkiE6cOOFOLseMGaN7771XAwcOVIcOHRQREaFbb731rNedM2eObrvtNj388MNq0qSJ7r//fuXn50uSLrroIj3xxBMaP368YmNjNXz4cEnSk08+qQkTJiglJUVNmzbVjTfeqI8++kj169eXJNWtW1fvvfee0tLS1KpVK82dO1fTpk2rwN8OAFQODutMT8EDAAAApURSCQAAAGM0lQAAADBGUwkAAABjNJUAAAAwRlMJAAAAYzSVAAAAMEZTCQAAAGM0lQAAADBGUwkAAABjNJUAAAAwRlMJAAAAYzSVAAAAMPb/AJVT2ldS4/KoAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}